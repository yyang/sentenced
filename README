A.The package can be compiled by make command:
To compile it, use the command below:
make calc
make trainCorpus
make clean

B.To calculate the similarity between two sentences, use the command below:
./calc 's1' 's2'
sample:
./calc 'c plus plus is agile, robust and powerful'  'java is easy and powerful but not agile'
where s1 and s2 is the sentence to be compared.
Attention:
Avoid including ' in s1 and s2 cause it will split the input data.

C.There are three dictionaries
1. stop words.txt  
It's used to store the meaningless words in English, like 'hello', 'and', 'at'.etc.

2. symbols.txt
It's used to store the symbols in English,  like ', ',  '.', '!' and so on.

3. idf_dict.txt
It's used to store the most words' document frequency after training the corpus of tweets.1-3.data

D.To train the corpus ,  use the command below:
./trainCorpus train_data train_result
sample:
./trainCorpus tweets.2.data idf_dict_test.txt
Notice that the training process is time consuming which needs about 1 hour for each data file.


Performance:
a.For the similarity calcuation, normal CPU with memory of 1G is enough.
It takes about 18s to load all the dictionary into memory,  but the calculation process nearly costs 0 seconds.
b.For the training process,  it needs normal CPU with memory of 2G or more.(Perhaps 1G is OK , but it's slow)
During the process, it will print the line number being processed currently,  for each document of tweets.1-3.data, 
there are about 1000000 lines.
It takes about 1 hour to finish the training. Acturally I am trying to implement a asynchronized method, which is not finished yet.

It's now version 1.0.1, you can contact me for more evaluation as soon as possible.
